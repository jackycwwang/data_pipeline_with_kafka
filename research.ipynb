{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"mysql+pymysql://mysql:mysql@localhost:3307/buy_online_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy_online_db\n",
      "information_schema\n",
      "performance_schema\n"
     ]
    }
   ],
   "source": [
    "# Execute a query to fetch the list of databases\n",
    "query = text(\"SHOW DATABASES\")\n",
    "result = connection.execute(query)\n",
    "\n",
    "# Iterate through the result and print the database names\n",
    "for row in result:\n",
    "    print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Table, Column, Integer, String, Float, MetaData, TIMESTAMP\n",
    "from sqlalchemy.sql import text\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://mysql:mysql@localhost:3307/buy_online_db\")\n",
    "\n",
    "# Define the metadata object\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define a table within the metadata object\n",
    "test = Table(\n",
    "    'test',\n",
    "    metadata,\n",
    "    Column('id', Integer, primary_key=True),\n",
    "    Column('username', String(100)),\n",
    "    Column('email', String(100))\n",
    ")\n",
    "\n",
    "# Create the table in the database (generates SQL)\n",
    "metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asyncio import wait_for\n",
    "import pymysql\n",
    "import time\n",
    "from retrying import retry\n",
    "\n",
    "host=\"localhost\"\n",
    "user=\"mysql\"\n",
    "password=\"mysql\"\n",
    "database=\"buy_online_db\"\n",
    "port=3307\n",
    "\n",
    "@retry(stop_max_attempt_number=10, wait_fixed=2000,\n",
    "       retry_on_exception=lambda e: isinstance(e, pymysql.MySQLError))\n",
    "def wait_for_mysql():\n",
    "    connection = pymysql.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"mysql\",\n",
    "        password=\"mysql\",\n",
    "        database=\"buy_online_db\",\n",
    "        port=3307,\n",
    "    )\n",
    "    connection.close()\n",
    "    print(\"MySQL is ready!\")\n",
    "\n",
    "try:\n",
    "    wait_for_mysql()\n",
    "except Exception as e:\n",
    "    print(\"Failed to connect to MySQL after multiple retries. Exiting.\")\n",
    "    exit(1)\n",
    "\n",
    "wait_for_mysql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL is ready!\n"
     ]
    }
   ],
   "source": [
    "from asyncio import wait_for\n",
    "import pymysql\n",
    "import time\n",
    "from retrying import retry\n",
    "\n",
    "host=\"localhost\"\n",
    "user=\"mysql\"\n",
    "password=\"mysql\"\n",
    "database=\"buy_online_db\"\n",
    "port=3307\n",
    "\n",
    "@retry(stop_max_attempt_number=20, wait_fixed=3500,\n",
    "       retry_on_exception=lambda e: isinstance(e, pymysql.MySQLError))\n",
    "def wait_for_mysql():\n",
    "  try:\n",
    "      connection = pymysql.connect(\n",
    "          host=host,\n",
    "          user=user,\n",
    "          password=password,\n",
    "          database=database,\n",
    "          port=port,\n",
    "      )\n",
    "      connection.close()\n",
    "      print(\"MySQL is ready!\")\n",
    "  except pymysql.MySQLError as e:\n",
    "      print(f\"MySQL is not ready yet: {e}\")\n",
    "      raise\n",
    "\n",
    "wait_for_mysql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL server is ready\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from retrying import retry\n",
    "\n",
    "@retry(stop_max_attempt_number=10, wait_fixed=2000,\n",
    "       retry_on_exception=lambda e: isinstance(e, mysql.connector.Error))\n",
    "def connect_to_mysql():\n",
    "    conn = mysql.connector.connect(\n",
    "        host='localhost',  # Use the MySQL service name as the hostname\n",
    "        user='mysql',\n",
    "        password='mysql',\n",
    "        database='buy_online_db',\n",
    "        port=3307,\n",
    "    )\n",
    "    conn.close()\n",
    "    print(\"MySQL server is ready\")\n",
    "\n",
    "try:\n",
    "    connect_to_mysql()\n",
    "except Exception as e:\n",
    "    print(\"Failed to connect to MySQL after multiple retries. Exiting.\")\n",
    "    exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# product_updater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT was successful\n"
     ]
    }
   ],
   "source": [
    "connection = engine.connect()\n",
    "insert_statement = test.insert().values(username='name', email='myname@example.com')\n",
    "result = connection.execute(insert_statement)\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "# Check if the INSERT was successful\n",
    "if result.rowcount == 1:\n",
    "    print(\"INSERT was successful\")\n",
    "else:\n",
    "    print(\"INSERT failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = './data/1429_1.csv'\n",
    "chunk_size = 50\n",
    "\n",
    "# Define a generator function to yield chunks of data\n",
    "def chunked_data_generator():\n",
    "    for chunk_df in pd.read_csv(file_path, chunksize=chunk_size, encoding='utf-8'):\n",
    "        yield chunk_df\n",
    "\n",
    "# Create a generator object\n",
    "data_generator = chunked_data_generator()\n",
    "\n",
    "# Iterate over the generator to get chunks of 50 rows at a time\n",
    "for chunk in data_generator:\n",
    "    # Process each chunk here\n",
    "    print(chunk.head())  # Example: Print the first 5 rows of each chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Table, Column, Integer, String, Float, MetaData, TIMESTAMP\n",
    "from sqlalchemy.sql import text\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://mysql:mysql@localhost:3307/buy_online_db\")\n",
    "connection = engine.connect()\n",
    "\n",
    "# Drop the table\n",
    "tbl_name = 'product'\n",
    "query = text(f\"drop table if exists {tbl_name}\")\n",
    "result = connection.execute(query)\n",
    "connection.commit()\n",
    "\n",
    "# Define the metadata object\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define a table within the metadata object\n",
    "# Define the product table schema\n",
    "product_table = Table('product', metadata,\n",
    "    Column('id', Integer, primary_key=True),\n",
    "    Column('name', String(300)),\n",
    "    Column('category', String(500)),\n",
    "    Column('price', Float),\n",
    "    Column('last_updated', TIMESTAMP)  # Use TIMESTAMP for the last_updated column\n",
    ")\n",
    "\n",
    "# Create the table in the database (generates SQL)\n",
    "metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/marketing_sample_for_walmart_com-ecommerce__20191201_20191231__30k_data.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Uniq Id          30000 non-null  object \n",
      " 1   Crawl Timestamp  30000 non-null  object \n",
      " 2   Product Url      30000 non-null  object \n",
      " 3   Product Name     30000 non-null  object \n",
      " 4   Description      29947 non-null  object \n",
      " 5   List Price       30000 non-null  float64\n",
      " 6   Sale Price       30000 non-null  float64\n",
      " 7   Brand            29436 non-null  object \n",
      " 8   Item Number      8875 non-null   float64\n",
      " 9   Gtin             30000 non-null  int64  \n",
      " 10  Package Size     0 non-null      float64\n",
      " 11  Category         29983 non-null  object \n",
      " 12  Postal Code      0 non-null      float64\n",
      " 13  Available        30000 non-null  bool   \n",
      "dtypes: bool(1), float64(5), int64(1), object(7)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniq Id</th>\n",
       "      <th>Crawl Timestamp</th>\n",
       "      <th>Product Url</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>List Price</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Item Number</th>\n",
       "      <th>Gtin</th>\n",
       "      <th>Package Size</th>\n",
       "      <th>Category</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>019b67ef7f01103d8fb0a53e4c36daa7</td>\n",
       "      <td>2019-12-18 10:20:52 +0000</td>\n",
       "      <td>https://www.walmart.com/ip/La-Costena-Chipotle...</td>\n",
       "      <td>La Costena Chipotle Peppers, 7 OZ (Pack of 12)</td>\n",
       "      <td>We aim to show you accurate product informati...</td>\n",
       "      <td>31.93</td>\n",
       "      <td>31.93</td>\n",
       "      <td>La Costeï¿½ï¿½a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139941530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Food | Meal Solutions, Grains &amp; Pasta | Canned...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3a4ff306dcc8a6e2bf720964d29b84c3</td>\n",
       "      <td>2019-12-18 17:21:48 +0000</td>\n",
       "      <td>https://www.walmart.com/ip/Equate-Triamcinolon...</td>\n",
       "      <td>Equate Triamcinolone Acetonide Nasal Allergy S...</td>\n",
       "      <td>We aim to show you accurate product informati...</td>\n",
       "      <td>10.48</td>\n",
       "      <td>10.48</td>\n",
       "      <td>Equate</td>\n",
       "      <td>569045548.0</td>\n",
       "      <td>632775553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health | Equate | Equate Allergy | Equate Sinu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80090549d7d176327b186353c7b28ca4</td>\n",
       "      <td>2019-12-18 17:46:41 +0000</td>\n",
       "      <td>https://www.walmart.com/ip/AduroSmart-ERIA-Sof...</td>\n",
       "      <td>AduroSmart ERIA Soft White Smart A19 Light Bul...</td>\n",
       "      <td>We aim to show you accurate product informati...</td>\n",
       "      <td>10.99</td>\n",
       "      <td>10.99</td>\n",
       "      <td>AduroSmart ERIA</td>\n",
       "      <td>568068849.0</td>\n",
       "      <td>281487005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronics | Smart Home | Smart Energy and Li...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151ee1c61a29bacfedb01cd500494b2f</td>\n",
       "      <td>2019-12-18 22:14:22 +0000</td>\n",
       "      <td>https://www.walmart.com/ip/24-Classic-Adjustab...</td>\n",
       "      <td>24\" Classic Adjustable Balloon Fender Set Chro...</td>\n",
       "      <td>We aim to show you accurate product informati...</td>\n",
       "      <td>38.59</td>\n",
       "      <td>38.59</td>\n",
       "      <td>lowrider</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133714060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sports &amp; Outdoors | Bikes | Bike Accessories |...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7b2ef8d41f65df121f6b4b9828cf8dad</td>\n",
       "      <td>2019-12-18 06:56:02 +0000</td>\n",
       "      <td>https://www.walmart.com/ip/Elephant-Shape-Sili...</td>\n",
       "      <td>Elephant Shape Silicone Drinkware Portable Sil...</td>\n",
       "      <td>We aim to show you accurate product informati...</td>\n",
       "      <td>5.81</td>\n",
       "      <td>5.81</td>\n",
       "      <td>Anself</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104042139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baby | Feeding | Sippy Cups: Alternatives to P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Uniq Id            Crawl Timestamp  \\\n",
       "0  019b67ef7f01103d8fb0a53e4c36daa7  2019-12-18 10:20:52 +0000   \n",
       "1  3a4ff306dcc8a6e2bf720964d29b84c3  2019-12-18 17:21:48 +0000   \n",
       "2  80090549d7d176327b186353c7b28ca4  2019-12-18 17:46:41 +0000   \n",
       "3  151ee1c61a29bacfedb01cd500494b2f  2019-12-18 22:14:22 +0000   \n",
       "4  7b2ef8d41f65df121f6b4b9828cf8dad  2019-12-18 06:56:02 +0000   \n",
       "\n",
       "                                         Product Url  \\\n",
       "0  https://www.walmart.com/ip/La-Costena-Chipotle...   \n",
       "1  https://www.walmart.com/ip/Equate-Triamcinolon...   \n",
       "2  https://www.walmart.com/ip/AduroSmart-ERIA-Sof...   \n",
       "3  https://www.walmart.com/ip/24-Classic-Adjustab...   \n",
       "4  https://www.walmart.com/ip/Elephant-Shape-Sili...   \n",
       "\n",
       "                                        Product Name  \\\n",
       "0     La Costena Chipotle Peppers, 7 OZ (Pack of 12)   \n",
       "1  Equate Triamcinolone Acetonide Nasal Allergy S...   \n",
       "2  AduroSmart ERIA Soft White Smart A19 Light Bul...   \n",
       "3  24\" Classic Adjustable Balloon Fender Set Chro...   \n",
       "4  Elephant Shape Silicone Drinkware Portable Sil...   \n",
       "\n",
       "                                         Description  List Price  Sale Price  \\\n",
       "0   We aim to show you accurate product informati...       31.93       31.93   \n",
       "1   We aim to show you accurate product informati...       10.48       10.48   \n",
       "2   We aim to show you accurate product informati...       10.99       10.99   \n",
       "3   We aim to show you accurate product informati...       38.59       38.59   \n",
       "4   We aim to show you accurate product informati...        5.81        5.81   \n",
       "\n",
       "             Brand  Item Number       Gtin  Package Size  \\\n",
       "0  La Costeï¿½ï¿½a          NaN  139941530           NaN   \n",
       "1           Equate  569045548.0  632775553           NaN   \n",
       "2  AduroSmart ERIA  568068849.0  281487005           NaN   \n",
       "3         lowrider          NaN  133714060           NaN   \n",
       "4           Anself          NaN  104042139           NaN   \n",
       "\n",
       "                                            Category  Postal Code  Available  \n",
       "0  Food | Meal Solutions, Grains & Pasta | Canned...          NaN       True  \n",
       "1  Health | Equate | Equate Allergy | Equate Sinu...          NaN       True  \n",
       "2  Electronics | Smart Home | Smart Energy and Li...          NaN       True  \n",
       "3  Sports & Outdoors | Bikes | Bike Accessories |...          NaN       True  \n",
       "4  Baby | Feeding | Sippy Cups: Alternatives to P...          NaN       True  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [02:29<00:00, 200.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, String, Float, TIMESTAMP, MetaData\n",
    "from sqlalchemy.sql import text\n",
    "import pymysql\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "logger = logging.getLogger(\"my_logger\")\n",
    "\n",
    "try:\n",
    "  engine = create_engine(\"mysql+pymysql://mysql:mysql@localhost:3307/buy_online_db\")\n",
    "  connection = engine.connect()\n",
    "except pymysql.Error:\n",
    "  logger.error(f\"Database connection error: {err}\")\n",
    "\n",
    "# Define the metadata\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define the product table schema\n",
    "product_table = Table('product', metadata,\n",
    "    Column('id', Integer, primary_key=True),\n",
    "    Column('name', String(300)),\n",
    "    Column('category', String(500)),\n",
    "    Column('price', Float),\n",
    "    Column('last_updated', TIMESTAMP)\n",
    ")\n",
    "\n",
    "file_path = './data/marketing_sample_for_walmart_com-ecommerce__20191201_20191231__30k_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.fillna(\"Uncategorized\", inplace=True)\n",
    "\n",
    "try:\n",
    "  for id, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "      uniq_id = str(id+1)\n",
    "      # print(f\"id={id}\")\n",
    "      name = row['Product Name']\n",
    "      cat = row['Category']\n",
    "      price = row['List Price']\n",
    "      datetime_str = row['Crawl Timestamp']\n",
    "      datetime_obj = datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S %z')\n",
    "      last_updated = datetime_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    except KeyError as key_err:\n",
    "      logger.error(f\"KeyError: {key_err}\")\n",
    "      continue\n",
    "    except ValueError as value_err:\n",
    "      logger.error(f\"ValueError: {value_err}\")\n",
    "      continue\n",
    "    except Exception as err:\n",
    "      logger.error(f\"An unexpected error occurred: {err}\")\n",
    "      continue\n",
    "\n",
    "    # Insert data into the product table\n",
    "    insert_query = product_table.insert().values(\n",
    "      id=uniq_id,\n",
    "      name=name,\n",
    "      category=cat,\n",
    "      price=price,\n",
    "      last_updated=last_updated\n",
    "    )\n",
    "\n",
    "    # Execute the query\n",
    "    connection.execute(insert_query)\n",
    "    connection.commit()\n",
    "    # break\n",
    "\n",
    "except Exception as err:\n",
    "    logger.error(f\"An unexpected error occurred: {err}\")\n",
    "finally:\n",
    "    # Close the connection\n",
    "    connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, String, Float, TIMESTAMP, MetaData\n",
    "from sqlalchemy.sql import text\n",
    "import pymysql\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import time\n",
    "\n",
    "logger = logging.getLogger(\"my_logger\")\n",
    "# hostname = \"172.25.184.208\"\n",
    "hostname = \"localhost\"\n",
    "port = \"3307\"\n",
    "\n",
    "try:\n",
    "  engine = create_engine(f\"mysql+pymysql://mysql:mysql@{hostname}:{port}/buy_online_db\")\n",
    "  connection = engine.connect()\n",
    "except pymysql.Error:\n",
    "  logger.error(f\"Database connection error: {err}\")\n",
    "\n",
    "# Define the metadata\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define the product table schema\n",
    "product_table = Table('product', metadata,\n",
    "    Column('id', Integer, primary_key=True),\n",
    "    Column('name', String(300)),\n",
    "    Column('category', String(500)),\n",
    "    Column('price', Float),\n",
    "    Column('last_updated', TIMESTAMP)\n",
    ")\n",
    "\n",
    "file_path = './data/products_update.csv'\n",
    "\n",
    "# Iterate through your data and insert it into the product table\n",
    "chunk_size = 15\n",
    "try:\n",
    "  with pd.read_csv(file_path, chunksize=chunk_size) as reader:\n",
    "    for chunk in reader:\n",
    "        for _, row in chunk.iterrows():\n",
    "          try:\n",
    "            id = row['id']\n",
    "            name = row['name']\n",
    "            cat = row['category']\n",
    "            price = row['price']\n",
    "            datetime_obj = datetime.strptime(row['last_updated'], '%Y-%m-%d %H:%M:%S')\n",
    "            last_updated = datetime_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "          except KeyError as key_err:\n",
    "            logger.error(f\"KeyError: {key_err}\")\n",
    "            continue\n",
    "          except ValueError as value_err:\n",
    "            logger.error(f\"ValueError: {value_err}\")\n",
    "            continue\n",
    "          except Exception as err:\n",
    "            logger.error(f\"An unexpected error occurred: {err}\")\n",
    "            continue\n",
    "\n",
    "          # Insert data into the product table\n",
    "          insert_query = product_table.insert().values(\n",
    "            id=id,\n",
    "            name=name,\n",
    "            category=cat,\n",
    "            price=price,\n",
    "            last_updated=last_updated\n",
    "          )\n",
    "\n",
    "          # Execute the query\n",
    "          connection.execute(insert_query)\n",
    "          connection.commit()\n",
    "          # time.sleep(0.5)\n",
    "        time.sleep(5)\n",
    "        # break\n",
    "\n",
    "except Exception as e:\n",
    "  logger.error(f\"Unexpected exception: {e}\")\n",
    "finally:\n",
    "  # Close the connection\n",
    "  connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Define your database connection parameters\n",
    "db_config = {\n",
    "    \"user\": \"mysql\",\n",
    "    \"password\": \"mysql\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 3307,\n",
    "    \"database\": \"buy_online_db\",\n",
    "}\n",
    "\n",
    "# Establish a connection to the database\n",
    "connection = mysql.connector.connect(**db_config)\n",
    "# dir(connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema_str: {\"type\":\"record\",\"name\":\"Product\",\"namespace\":\"com.buyonline.product\",\"fields\":[{\"name\":\"id\",\"type\":\"int\"},{\"name\":\"name\",\"type\":\"string\"},{\"name\":\"category\",\"type\":[\"null\",\"string\"],\"default\":null},{\"name\":\"price\",\"type\":\"double\"},{\"name\":\"last_updated\",\"type\":\"string\"}]}\n",
      "['__bool__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_key_serializer', '_value_serializer', 'abort_transaction', 'begin_transaction', 'commit_transaction', 'flush', 'init_transactions', 'list_topics', 'poll', 'produce', 'purge', 'send_offsets_to_transaction', 'set_sasl_credentials']\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "\n",
    "# import hydra\n",
    "# from omegaconf import OmegaConf, DictConfig\n",
    "\n",
    "from confluent_kafka import SerializingProducer\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.avro import AvroSerializer\n",
    "from confluent_kafka.serialization import StringSerializer\n",
    "\n",
    "config_path = 'conf/config.yaml'\n",
    "with open(config_path, 'r') as yaml_fp:\n",
    "    cfg = yaml.safe_load(yaml_fp)\n",
    "\n",
    "sr_cfg = cfg['schema_registry']\n",
    "kafka_cfg = cfg['kafka']\n",
    "\n",
    "# Create a Schema Registry client\n",
    "schema_registry_config = {\n",
    "    'url': sr_cfg['url'],\n",
    "    'basic.auth.user.info': '{}:{}'.format(sr_cfg['user'], sr_cfg['secret'])\n",
    "}\n",
    "schema_registry_client = SchemaRegistryClient(schema_registry_config)\n",
    "\n",
    "# Fetch the latest Avro schema for the value\n",
    "subject_name = 'product_updates-value'\n",
    "schema_str = schema_registry_client.get_latest_version(subject_name).schema.schema_str\n",
    "print('schema_str:',schema_str)\n",
    "\n",
    "# Create Avro Serializer for the value\n",
    "key_serializer = StringSerializer('utf_8')\n",
    "avro_serializer = AvroSerializer(schema_registry_client, schema_str)\n",
    "\n",
    "# Create a kafka producer\n",
    "kafka_config = {\n",
    "    'bootstrap.servers': kafka_cfg['bootstrap_servers'],\n",
    "    'sasl.mechanisms': kafka_cfg['sasl_mechanisms'],\n",
    "    'security.protocol': kafka_cfg['security_protocol'],\n",
    "    'sasl.username': kafka_cfg['sasl_username'],\n",
    "    'sasl.password': kafka_cfg['sasl_password'],\n",
    "    'key.serializer': key_serializer,\n",
    "    'value.serializer': avro_serializer\n",
    "}\n",
    "\n",
    "try:\n",
    "    producer = SerializingProducer(kafka_config)\n",
    "    print(dir(producer))\n",
    "\n",
    "except Exception as err:\n",
    "    logger.error(f\"Kafka cluster connection error: {err}\")\n",
    "\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    \"\"\"\n",
    "    Reports the failure or success of a message delivery.\n",
    "\n",
    "    Args:\n",
    "        err (KafkaError): The error that occurred on None on success.\n",
    "\n",
    "        msg (Message): The message that was produced or failed.\n",
    "\n",
    "    Note:\n",
    "        In the delivery report callback the Message.key() and Message.value()\n",
    "        will be the binary format as encoded by any configured Serializers and\n",
    "        not the same object that was passed to produce().\n",
    "        If you wish to pass the original object(s) for key and value to delivery\n",
    "        report callback we recommend a bound callback or lambda where you pass\n",
    "        the objects along.\n",
    "\n",
    "    \"\"\"\n",
    "    if err is not None:\n",
    "        print(\"Delivery failed for record {}: {}\".format(msg.key(), err))\n",
    "        return\n",
    "    print('User record {} successfully produced to {} [{}] at offset {}'.format(\n",
    "        msg.key(), msg.topic(), msg.partition(), msg.offset()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = \"time_track/last_read_timestamp.json\"\n",
    "with open(filename, \"r\") as fp:\n",
    "  try:\n",
    "    last_read = json.load(fp)\n",
    "  except json.JSONDecodeError:\n",
    "    last_read = {'last_read_timestamp': None}\n",
    "\n",
    "last_read_timestamp = last_read.get('last_read_timestamp', None)\n",
    "if last_read_timestamp is None:\n",
    "  with open(filename, 'w') as fp:\n",
    "    last_read_timestamp = '2015-12-18 23:53:48'\n",
    "    last_read['last_read_timestamp'] = last_read_timestamp\n",
    "    json.dump(last_read, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_read_timestamp': '2015-01-01 00:00:00'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1, Name: Product_1, Category: Cat_1, Price: 40.6, Last Updated: 2023-10-13 10:01:05\n",
      "User record b'1' successfully produced to product_updates [3] at offset 0\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "\n",
    "# Create a cursor to execute SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Define the timezone for your datetime objects\n",
    "# tz = pytz.timezone('America/New_York')\n",
    "\n",
    "# last_read_obj = tz.localize(datetime.strptime(last_read_timestamp, '%Y-%m-%d %H:%M:%S'))\n",
    "last_read_obj = datetime.strptime(last_read_timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Define SQL query as a string\n",
    "sql_query = \"\"\"\n",
    "    SELECT id, name, category, price, last_updated\n",
    "    FROM product\n",
    "    WHERE last_updated > %s\n",
    "    limit 1\n",
    "\"\"\"\n",
    "try:\n",
    "    # while True:\n",
    "        # Execute the SQL query\n",
    "        cursor.execute(sql_query, (last_read_obj,))\n",
    "\n",
    "        # Fetch all rows from the result set\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        # Iterate through the rows and print the values\n",
    "        if rows:\n",
    "            for row in rows:\n",
    "                id, name, category, price, last_updated = row\n",
    "                # last_updated = last_updated.astimezone(tz)\n",
    "                print(f\"ID: {id}, Name: {name}, Category: {category}, Price: {price}, Last Updated: {last_updated}\")\n",
    "\n",
    "                # columns = [column[0] for column in cursor.description]\n",
    "                # value = dict(zip(columns, row))\n",
    "\n",
    "                value = {\n",
    "                    'id': id,\n",
    "                    'name': name,\n",
    "                    'category': category,\n",
    "                    'price': price,\n",
    "                    'last_updated': last_updated.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                }\n",
    "\n",
    "                producer.produce(topic='product_updates',\n",
    "                                key=str(id),\n",
    "                                value=value,\n",
    "                                on_delivery=delivery_report)\n",
    "                producer.flush()  # may become blocking in a long run\n",
    "\n",
    "                if last_updated > last_read_obj:\n",
    "                    last_read_obj = last_updated\n",
    "\n",
    "\n",
    "            with open(filename, 'w') as fp:\n",
    "                last_read['last_read_timestamp'] = last_read_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                json.dump(last_read, fp)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and the database connection\n",
    "    cursor.close()\n",
    "    connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 10, 13, 10, 1, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_read_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema_str: {\"type\":\"record\",\"name\":\"Product\",\"namespace\":\"com.buyonline.product\",\"fields\":[{\"name\":\"id\",\"type\":\"int\"},{\"name\":\"name\",\"type\":\"string\"},{\"name\":\"category\",\"type\":[\"null\",\"string\"],\"default\":null},{\"name\":\"price\",\"type\":\"double\"},{\"name\":\"last_updated\",\"type\":\"string\"}]}\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_key_deserializer', '_value_deserializer', 'assign', 'assignment', 'close', 'commit', 'committed', 'consume', 'consumer_group_metadata', 'get_watermark_offsets', 'incremental_assign', 'incremental_unassign', 'list_topics', 'memberid', 'offsets_for_times', 'pause', 'poll', 'position', 'resume', 'seek', 'set_sasl_credentials', 'store_offsets', 'subscribe', 'unassign', 'unsubscribe']\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import json\n",
    "import threading\n",
    "\n",
    "from confluent_kafka import DeserializingConsumer\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.avro import AvroDeserializer\n",
    "from confluent_kafka.serialization import StringDeserializer\n",
    "\n",
    "# import hydra\n",
    "# from omegaconf import OmegaConf, DictConfig\n",
    "import yaml\n",
    "\n",
    "logger = logging.getLogger(\"consumer_logger\")\n",
    "\n",
    "cfg_path = 'conf/config.yaml'\n",
    "with open(cfg_path, 'r') as yaml_fp:\n",
    "  cfg = yaml.safe_load(yaml_fp)\n",
    "sr_cfg = cfg['schema_registry']\n",
    "kafka_cfg = cfg['kafka']\n",
    "\n",
    "\n",
    "# Create a Schema Registry client\n",
    "schema_registry_client = SchemaRegistryClient({\n",
    "  'url': sr_cfg['url'],\n",
    "  'basic.auth.user.info': '{}:{}'.format(sr_cfg['user'], sr_cfg['secret'])\n",
    "})\n",
    "\n",
    "# Fetch the latest Avro schema for the value\n",
    "subject_name = 'product_updates-value'\n",
    "schema_str = schema_registry_client.get_latest_version(subject_name).schema.schema_str\n",
    "print('schema_str:',schema_str)\n",
    "\n",
    "# Create Avro Deserializer for the value\n",
    "key_deserializer = StringDeserializer('utf_8')\n",
    "avro_deserializer = AvroDeserializer(schema_registry_client, schema_str)\n",
    "\n",
    "# Define Kafka configuration\n",
    "kafka_config = {\n",
    "    'bootstrap.servers': kafka_cfg['bootstrap_servers'],\n",
    "    'sasl.mechanisms': kafka_cfg['sasl_mechanisms'],\n",
    "    'security.protocol': kafka_cfg['security_protocol'],\n",
    "    'sasl.username': kafka_cfg['sasl_username'],\n",
    "    'sasl.password': kafka_cfg['sasl_password'],\n",
    "    'key.deserializer': key_deserializer,\n",
    "    'value.deserializer': avro_deserializer,\n",
    "    'group.id': 'consumer_group5',\n",
    "    'auto.offset.reset': 'earliest',\n",
    "    'max.poll.interval.ms': 6000000,\n",
    "    # 'enable.auto.commit': True,      # default value\n",
    "    # 'auto.commit.interval.ms': 5000, # Commit every 5000 ms, i.e., every 5 seconds\n",
    "}\n",
    "\n",
    "# Define the DeserializingConsumer\n",
    "try:\n",
    "    consumer = DeserializingConsumer(kafka_config)\n",
    "except Exception as e:\n",
    "  logger.error(f\"Kafka connection failed: {e}\")\n",
    "\n",
    "# Subscribe to the 'retail_data' topic\n",
    "consumer.subscribe(['product_updates'])\n",
    "print(dir(consumer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "log_path = './consumer_log/consumer_log.json'\n",
    "if not os.path.exists(log_path):\n",
    "    updates = {'update_logs': []}\n",
    "else:\n",
    "    try:\n",
    "        with open(log_path, 'r') as log_fp:\n",
    "            updates = json.load(log_fp)\n",
    "    except FileNotFoundError as file_err:\n",
    "        logger.error(f\"File not found: {file_err}\")\n",
    "    except json.JSONDecodeError as json_err:\n",
    "        logger.error(f\"JSON Read error: {json_err}\")\n",
    "        updates = {'update_logs': []}\n",
    "    except Exception as err:\n",
    "        logger.error(f\"An error occurred: {err}\")\n",
    "\n",
    "# id_path = './consumer_log/id_log.json'\n",
    "# if not os.path.exists(id_path):\n",
    "#     ids = {}\n",
    "# else:\n",
    "#     with open(id_path, 'r') as id_fp:\n",
    "#         ids = json.load(id_fp)\n",
    "\n",
    "discount = 0.8\n",
    "try:\n",
    "    while True:\n",
    "        msg = consumer.poll(1.0)\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            print('Consumer error: {}'.format(msg.error()))\n",
    "            continue\n",
    "\n",
    "        value = msg.value()\n",
    "        category = value['category']\n",
    "        value['category'] = category.upper()\n",
    "        value['discount_price'] = 'na'\n",
    "        if category == 'Cat_5':\n",
    "            value['discount_price'] = value['price'] * discount\n",
    "\n",
    "        # id = value['id']\n",
    "        # if value['id'] not in ids:\n",
    "        try:\n",
    "            updates['update_logs'].append(value)\n",
    "            with open(log_path, 'w') as log_fp:\n",
    "                json.dump(updates, log_fp, indent=2)\n",
    "        except FileNotFoundError as file_err:\n",
    "            print(f\"Error: {log_path} not found.\")\n",
    "        except json.JSONDecodeError as json_err:\n",
    "            print(f\"JSON Write error: {json_err}\")\n",
    "        except Exception as err:\n",
    "            print(f\"An error occurred: {err}\")\n",
    "\n",
    "        logger.info('Successfully consumed record with key {} and value {}'.format(msg.key(), msg.value()))\n",
    "\n",
    "            # ids[id] = value['last_updated']\n",
    "            # with open(id_path, 'w') as id_fp:\n",
    "                # json.dump(ids, id_fp)\n",
    "\n",
    "        # time.sleep(30)\n",
    "        #consumer.commitSync()\n",
    "        #consumer.commitAsync()\n",
    "except Exception as e:\n",
    "  logger.error(f\"Un unexpected error occurred: {e}\")\n",
    "\n",
    "# finally:\n",
    "  # consumer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-deg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
